Разработать Django приложение для обработки и агрегации Apache лога.

В составе приложения должна быть Management command которая на вход принимает ссылку на лог файл определенного формата, скачивает ее, парсит и записывает в DB. При загрузке, обработке и записи данных в DB нужно выводить прогресс бар.


Ссылка для теста http://www.almhuette-raith.at/apache-log/access.log (размер файла 186 Мб)


В приложении должна быть модель в которой будет храниться распарсенные данные из лога. Поля модели должны содержать минимум: IP адрес, Дата из лога, http метод (GET, POST,...), URI запроса, Код ошибки, Размер ответа. Другие данные из лога - опциональны.


На фронтенд необходимо реализовать вывод данных из модели, с пагинацией (50 записей на страницу) и поиском.


Под таблицей так-же необходимо вывести статистику которая будет содержать следующие данные:

    Количество уникальных IP

    Top 10 самых распространенных IP адресов, в формате таблички где указан IP адрес и количество его вхождений

    Количество GET, POST, ... (http методов) 

    Общее кол-во переданных байт (суммарное значение по полю "размер ответа")


Учесть что эти агрегированные данные должны меняться при использовании поиске.


Плюсами будут (опционально):

    Хорошее оформление и комментирование кода (не излишнее но хорошее);

    Оформление frontend части;

    Упаковка проекта в docker/docker-compose ;

    Оптимизация запросов к БД;

    Кнопка экспорта данных на таблице с результатами, при нажатии на которую будет скачиваться файлик в формате XLSX с результатами выдачи;

    
    Посмотрели тестовое задание, вот выявленные проблемы:
    Требовалось создать законченное приложение, а не модуль который нужно подключать в свое приложение. Я не могу запустить его так как нету самого приложения (manage.py, settings и так далее)
    Зачем разделять загрузку лога и его парсинг и импорт
    Нельзя использовать файл access.log в качестве временного хранилища. Для этого есть модуль tempfile (а вдруг 2 одновременно запустятся процесса импорта)
    В HTTP есть другие методы, кроме POST и GET
    Странное и по сути не верное решение по парсингу данных из лога
    Очень странное вычисление каждой 1000 записей - if str(count_str).endswith('000')
    Метод parse_date - чудовищен. Для этого обычно используется метод  datetime.strptime
    В модели, для полей ip и url резонно использоваться специфические типы данных
    В модели не указан под класс Meta и не указаны verbose_name у полей
    Шаблон HTML не валиден. Нет <html><head><body> не указан csrf_token для формы
    Нет пагинации
    Аггрегации ужасны, сделаны через Python и тормозят. list_ip = query_log.values_list('ip'); sum_unique_ip = len(set(list_ip)) - пример как делать не надо :)
    В методе export_log повтор получения queryset. Зачем? Для этого же есть метод описанный выше.
    Есть форма SearchForm но она по сути никак не используется. А что если пользователь передаст в поиск 1000 знаков вместо 100 как положено? form.is_valid я нигде не нашел.


=====
Parser_log
=====

Parser_log is a Django app for or data processing and aggregation the Apache log.


Quick start
-----------

1. Add "parser_log" to your INSTALLED_APPS setting like this::

    INSTALLED_APPS = [
        ...
        'parser_log',
    ]

2. Include the log_doctor URLconf in your project urls.py like this::

    path(r'^log/', include('parser_log.urls')),

3. Run `python manage.py migrate` to create the parser_log models.

4. Run python manage.py downloadlog url\to\logfile\Apache. 
   (example "python manage.py downloadlog http://www.almhuette-raith.at/apache-log/access.log")

5. Start the development server and visit http://127.0.0.1:8000/log/
   to view aggregated information about the log file