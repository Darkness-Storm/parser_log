Разработать Django приложение для обработки и агрегации Apache лога.

В составе приложения должна быть Management command которая на вход принимает ссылку на лог файл определенного формата, скачивает ее, парсит и записывает в DB. При загрузке, обработке и записи данных в DB нужно выводить прогресс бар.


Ссылка для теста http://www.almhuette-raith.at/apache-log/access.log (размер файла 186 Мб)


В приложении должна быть модель в которой будет храниться распарсенные данные из лога. Поля модели должны содержать минимум: IP адрес, Дата из лога, http метод (GET, POST,...), URI запроса, Код ошибки, Размер ответа. Другие данные из лога - опциональны.


На фронтенд необходимо реализовать вывод данных из модели, с пагинацией (50 записей на страницу) и поиском.


Под таблицей так-же необходимо вывести статистику которая будет содержать следующие данные:

    Количество уникальных IP

    Top 10 самых распространенных IP адресов, в формате таблички где указан IP адрес и количество его вхождений

    Количество GET, POST, ... (http методов)

    Общее кол-во переданных байт (суммарное значение по полю "размер ответа")


Учесть что эти агрегированные данные должны меняться при использовании поиске.


Плюсами будут (опционально):

    Хорошее оформление и комментирование кода (не излишнее но хорошее);

    Оформление frontend части;

    Упаковка проекта в docker/docker-compose ;

    Оптимизация запросов к БД;

    Кнопка экспорта данных на таблице с результатами, при нажатии на которую будет скачиваться файлик в формате XLSX с результатами выдачи;


Посмотрели тестовое задание, вот выявленные проблемы:
1. Требовалось создать законченное приложение, а не модуль который нужно подключать в свое приложение. Я не могу запустить его так как нету самого приложения (manage.py, settings и так далее)
2. Зачем разделять загрузку лога и его парсинг и импорт
3. Нельзя использовать файл access.log в качестве временного хранилища. Для этого есть модуль tempfile (а вдруг 2 одновременно запустятся процесса импорта)
4. В HTTP есть другие методы, кроме POST и GET
5. Странное и по сути не верное решение по парсингу данных из лога
6. Очень странное вычисление каждой 1000 записей - if str(count_str).endswith('000')
7. Метод parse_date - чудовищен. Для этого обычно используется метод  datetime.strptime
8. В модели, для полей ip и url резонно использоваться специфические типы данных
9. В модели не указан под класс Meta и не указаны verbose_name у полей
10. Шаблон HTML не валиден. Нет <html><head><body>
11. не указан csrf_token для формы (не согласен: в нем нет смысла)
12. Нет пагинации
13. Аггрегации ужасны, сделаны через Python и тормозят. list_ip = query_log.values_list('ip'); sum_unique_ip = len(set(list_ip)) - пример как делать не надо :)
14. В методе export_log повтор получения queryset. Зачем? Для этого же есть метод описанный выше.
15. Есть форма SearchForm но она по сути никак не используется. А что если пользователь передаст в поиск 1000 знаков вместо 100 как положено? form.is_valid я нигде не нашел.
